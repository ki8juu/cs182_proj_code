model:
    family: lstm_attention
    n_embd: 256
    n_layer: 12
    n_head: 8
    lstm_hidden_dim: 512
    lstm_num_layers: 2
    lstm_dropout: 0.1
    attn_num_heads: 4
    attn_dropout: 0.0
    lstm_match_transformer_params: true
